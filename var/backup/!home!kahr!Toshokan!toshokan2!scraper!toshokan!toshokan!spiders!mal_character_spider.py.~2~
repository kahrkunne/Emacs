import scrapy
import logging

class MALCharacterSpider(scrapy.Spider):
    """Scraper for character pages on MyAnimeList."""
    name = "MAL_character"
    def __init__(self,  *args, **kwargs):
        super(MALCharacterSpider, self).__init__(*args, **kwargs)
        logging.getLogger('scrapy').setLevel(logging.WARNING)

    def start_requests(self):
        for character_id in range(1, 1001):
            yield scrapy.Request(url=self.settings["MAL_CHARACTER_PATH"] % str(character_id),
                                 callback=self.parse)

    def parse(self, response):
        # URL: of the format "file:///character/ID.html"
        mal_id = int(response.url.split('/')[-1].split(".")[0])
        is404 = response.xpath('//*[@id="content"]/div[@class="badresult"]/text()').extract_first()
        if is404 == "Invalid ID provided.":
            print("%s %s"%(str(mal_id), is404))
            yield None
            return
        # Different kinds of names
        name_with_nickname = response.xpath("//*[@id='contentWrapper']/div[1]/h1/text()").extract_first()

        name_header = response.xpath("//*[@id='content']/table/tr/td[2]/div[3]").extract_first()
        try:
            name_english = name_header.split(">")[1].split(" <")[0]
        except:
            name_english = ''

        try:
            name_japanese = name_header.split(">(")[1].split(")<")[0]
        except:
            name_japanese = ''

        description = ''

        for x in response.xpath("//*[@id='content']/table/tr/td[2]/text()").extract():
            if x == '\r\n':
                description += x
            else:
                s = x.strip()
                if s:
                    description += s

        main_img = response.xpath("//*[@id='content']/table/tr/td[1]/div[1]/a/img/@src").extract_first()

        yield {'mal_id':mal_id, 'name_with_nickname':name_with_nickname, 'name_english':name_english,
               'name_japanese':name_japanese, 'description':description, 'main_img':main_img}
