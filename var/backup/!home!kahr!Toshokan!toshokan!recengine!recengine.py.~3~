import sys
from collections import defaultdict
import csv
import re

import numpy as np
import scipy.sparse as sp
from lightfm.evaluation import precision_at_k, recall_at_k, auc_score, reciprocal_rank
from lightfm import LightFM
from random import random
from sklearn.feature_extraction import DictVectorizer

sys.path.append('/home/kahr/Toshokan/toshokan/app')
import models

def build_feature_dict(session, anime):
    d = {}
    links = session.query(models.Link).filter_by(main_kind='anime', main_id=anime.uid).all()
    studios = [session.query(models.Company).filter_by(uid=x.company_id).first().name
               for x in links if x.company_id and x.company_desc == 'Studio']
    genres = [session.query(models.Genre).filter_by(uid=x.genre_id).first().name
              for x in links if x.genre_id]
    directors = [session.query(models.Person).filter_by(uid=x.person_id).first().name
                 .replace(', ','')
                 for x in links if x.person_desc and re.match('^Director', x.person_desc)]

    for studio in studios:
        d['studio_{}'.format(studio)] = 1

    for genre in genres:
        d['genre_{}'.format(genre)] = 1

    for director in directors:
        d['director_{}'.format(director)] = 1

    return d

def gen_item_feature_matrix(session, num_shows):
    dv = DictVectorizer()

    l = [{}] * (num_shows + 1)
    anime = session.query(models.Anime)
    for a in anime:
        if a.uid <= num_shows:
            k = build_feature_dict(session, a)
            l[a.uid] = build_feature_dict(session, a)

    item_features = dv.fit_transform(l)

    eye = sp.eye(item_features.shape[0], item_features.shape[0]).tocsr()
    item_features_concat = sp.hstack((eye, item_features))
    item_features_concat = item_features_concat.tocsr().astype(np.float32)
    return dv, item_features_concat, item_features

def gen_model(learning_rate=0.07695958, no_components=50, alpha=6.841538e-05):
    return LightFM(loss='warp', learning_rate=learning_rate, no_components=no_components,
                   user_alpha=alpha, item_alpha=alpha)

def gen_interaction_csv(session, min_rating=1, implicit=False, filename='interactions.csv'):
    entries = session.query(models.OldAnimeEntry).yield_per(100000)
    with open(filename, 'w+') as f:
        for e in entries:
            if implicit:
                score = 1
            else:
                score = e.score

            if score < min_rating:
                continue

            f.write('{},{},{}\n'.format(e.name, e.anime_id, score))

def parse_interaction_csv(filename='interactions.csv', min_rating=1,
                          implicit=False, test=False, fraction=1):
    def _build_interaction_matrix(rows, cols, data):
        mat = sp.lil_matrix((rows, cols), dtype=np.int32)

        for uid, iid, rating in data:
            if rating >= min_rating:
                mat[uid, iid] = rating

        return mat.tocoo()

    data = []
    with open(filename, 'r') as f:
        for row in csv.reader(f, delimiter=','):
            data.append((row[0], int(row[1]), int(row[2])))

    usernumbers = {}
    useritems = defaultdict(list)
    bigcol = 0
    count = 0
    testdata = []
    traindata = []
    allitems = []
    count = 0
    prevname = ''
    if fraction:
        data = data[:int(len(data) * fraction)]
    for e in data:
        if e[0] != prevname:
            prevname = e[0]
            count += 1

        usernumbers.setdefault(e[0], count)
        useritems[e[0]].append(e[1])

        if e[1] not in allitems:
            allitems.append(e[1])

        if e[1] > bigcol:
            bigcol = e[1]

        if implicit:
            score = 1
        else:
            score = e[2]

        if random() > 0.8 and test:
            testdata.append((count, e[1], score))
        else:
            traindata.append((count, e[1], score))

    bigrow = count + 1
    bigcol = bigcol + 1 # FIXME why?

    test = _build_interaction_matrix(bigrow, bigcol, testdata)
    train = _build_interaction_matrix(bigrow, bigcol, traindata)

    return (train, test, usernumbers, useritems)


def gen_anime_id_map(session):
    entries = session.query(models.Anime).yield_per(100000)
    out = {}
    for e in entries:
        out[e.uid] = e.name
    return out

def get_anime_genres(session, aid):
    genre_ids = [x[0] for x in session.query(models.Link.genre_id).filter_by(anime_id=aid).all() if x[0]]
    genre_names = {}
    for gid in genre_ids:
        genre_names[gid] = session.query(models.Genre.name).filter_by(uid=gid).first()[0]

    return genre_names

def sample_recommendation_lightfm(model, user_id, num_items, item_features=None, skiplist=[], namemap=None, display=True, disp_count=3):

    item_ids = np.arange(num_items)
    scores = model.predict(user_id, item_ids, item_features=item_features)
    top_items = np.argsort(-scores)

    print("User %s" % user_id)
    print("     Recommended:")

    disp = 0
    if display:
        for x in top_items:
            if disp < disp_count and x not in skiplist:
                if namemap:
                    x = namemap[x]
                print("        %s" % x)
                disp += 1

    return top_items

def evaluate(model, train, test, pk=5, rk=10, item_features=None):
    print("[Precision@k] Train precision: %.2f"
          % precision_at_k(model, train, k=pk, num_threads=8, item_features=item_features).mean())
    print("[Precision@k] Test precision: %.2f"
          % precision_at_k(model, test, k=pk, num_threads=8, item_features=item_features).mean())

    print("[Recall@k] Train precision: %.2f"
          % recall_at_k(model, train, k=rk, num_threads=8, item_features=item_features).mean())
    print("[Recall@k] Test precision: %.2f"
          % recall_at_k(model, test, k=rk, num_threads=8, item_features=item_features).mean())

    print("[AUC] Train precision: %.2f"
          % auc_score(model, train, num_threads=8, item_features=item_features).mean())
    print("[AUC] Test precision: %.2f"
          % auc_score(model, test, num_threads=8, item_features=item_features).mean())

    print("[Reciprocal Rank] Train precision: %.2f"
          % reciprocal_rank(model, train, num_threads=8, item_features=item_features).mean())
    print("[Reciprocal Rank] Test precision: %.2f"
          % reciprocal_rank(model, test, num_threads=8, item_features=item_features).mean())

def objective(params):
    # unpack
    epochs, learning_rate,\
    no_components, alpha = params
    
    user_alpha = alpha
    item_alpha = alpha
    model = LightFM(loss='warp',
                    random_state=2016,
                    learning_rate=learning_rate,
                    no_components=no_components,
                    user_alpha=user_alpha,
                    item_alpha=item_alpha)
    model.fit(train, epochs=epochs,
              num_threads=8, verbose=False)
    
    patks = lightfm.evaluation.precision_at_k(model, test,
                                              train_interactions=None,
                                              k=5, num_threads=8)
    mapatk = np.mean(patks)
    # Make negative because we want to _minimize_ objective
    out = -mapatk
    # Handle some weird numerical shit going on
    if np.abs(out + 1) < 0.01 or out < -1.0:
        return 0.0
    else:
        return out

def cosine_similarity(vec, mat):
    sim = vec.dot(mat.T)
    matnorm = np.linalg.norm(mat, axis=1)
    vecnorm = np.linalg.norm(vec)
    return np.squeeze(sim / matnorm / vecnorm)

def best_match_by_tag(tag, voc, embds, features, disp_count=10, namemap=None, domain=None, reverse=False):
    idx = voc[tag] + features.shape[0]
    vec = embds[[idx], :]
    reprs = features.dot(embds)
    sims = cosine_similarity(vec, reprs)
    matches = np.argsort(-sims)

    if reverse:
        matches = matches[::-1]

    c = 0
    for m in matches:
        if c == disp_count:
            break

        if domain and m not in domain:
            continue

        if namemap:
            print(namemap[m])
        else:
            print(m)

        c += 1

    return matches
